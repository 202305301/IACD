{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import sklearn \n",
    "\n",
    "\n",
    "#Lê o arquivo CSV hcc_dataset.csv com a vírgula como delimitador e armazena os dados num DataFrame: df.\n",
    "df = pd.read_csv(\"hcc_dataset.csv\", sep=\",\")\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ad14716b5cc9c85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtém o número de Características e Dados\n",
    "num_caracteristicas = df.shape[1]\n",
    "num_dados = df.shape[0] \n",
    "\n",
    "print(f\"Número de Características: {num_caracteristicas}\")\n",
    "print(f\"Número de Dados: {num_dados}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c650e42d1088b98e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Obtem a lista de Características analisadas (colunas do df) \n",
    "print(\"Lista de Características analisadas:\")\n",
    "lista_colunas = []\n",
    "for coluna in df.columns:\n",
    "    lista_colunas.append(coluna)\n",
    "print(lista_colunas)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a46cc86d3d574b18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Cria um dicionário vazio para guardar o número de valores ausentes (representados por '?') para cada coluna do DataFrame.\n",
    "valores_ausentes_por_coluna = {}\n",
    "\n",
    "# Iterar sobre as colunas\n",
    "for coluna in df.columns:\n",
    "    # Inicializar contador para esta coluna\n",
    "    count = 0\n",
    "    # Iterar sobre os valores da coluna\n",
    "    for valor in df[coluna]:\n",
    "        # Se o valor for '?', incrementar o contador\n",
    "        if valor == '?':\n",
    "            count += 1\n",
    "    # Adicionar o contador ao dicionário\n",
    "    valores_ausentes_por_coluna[coluna] = count\n",
    "\n",
    "# Mostrar o resultado\n",
    "print(\"Valores Ausentes por Característica:\")\n",
    "for coluna, count in valores_ausentes_por_coluna.items():\n",
    "    print(f\"{coluna}: {count}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "162b0539aa96c288"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Abre o arquivo CSV original para leitura\n",
    "with open('hcc_dataset.csv', 'r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    rows = list(reader) #Lê todas as linhas do arquivo e armazena-as no arquivo\n",
    "\n",
    "# Abre um novo arquivo CSV para escrita\n",
    "with open('hcc_dataset_modified.csv', 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # Percorre cada linha do arquivo original\n",
    "    for row in rows:\n",
    "        #Inicializa uma nova linha para armazenar os valores modificados\n",
    "        new_row = []\n",
    "        # Percorre cada valor na linha original\n",
    "        for value in row:\n",
    "            #Substitui '?' por 'NaN'\n",
    "            if value == '?':\n",
    "                new_row.append('NaN')\n",
    "            #Substui 'None' por 'Non' \n",
    "            elif value == 'None':\n",
    "                new_row.append('Non') #tivemos de o fazer senão a substituição dos '?' por 'NaN' era mal feita \n",
    "            else:\n",
    "                new_row.append(value) # Mantém o valor original se não precisar de substituição\n",
    "        writer.writerow(new_row) # Escreve a nova linha modificada no arquivo de saída\n",
    "\n",
    "data= pd.read_csv(\"hcc_dataset_modified.csv\") # Lê o novo arquivo CSV modificado em um DataFrame do Pandas\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d925a286f4a4e7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calcula os tipos de dados de cada variável\n",
    "tipos = data.dtypes\n",
    "\n",
    "# Calcula o número de valores NaN em cada coluna\n",
    "num_nan = data.isna().sum()\n",
    "\n",
    "# Calcula a percentagem de valores NaN, em relação ao total, em cada coluna\n",
    "percentagem_nan = (num_nan / len(data)) * 100\n",
    "percentagem_nan_formatada = percentagem_nan.apply(lambda x: f\"{x:.2f}%\") #percentagem formatada com 2 casas decimais\n",
    "\n",
    "# Cria um DataFrame para armazenar as estatísticas\n",
    "tabela_estatisticas = pd.DataFrame({\n",
    "    'Tipo': tipos,\n",
    "    'Média/Moda': '-', # Inicializa com '-' para preencher posteriormente \n",
    "    'Desvio_Padrão (%)': '-',\n",
    "    'Máximo': '-',\n",
    "    'Mínimo': '-',\n",
    "    'NaN': num_nan,\n",
    "    'NaN (%)': percentagem_nan_formatada\n",
    "})\n",
    "\n",
    "#Seleciona as colunas numéricas do df\n",
    "colunas_numericas = data.select_dtypes(include=[np.number]).columns\n",
    "# Calcula a média, desvio padrão, máximo e mínimo para colunas numéricas\n",
    "for coluna in colunas_numericas:\n",
    "    media = data[coluna].mean()\n",
    "    desvio_padrao = data[coluna].std()\n",
    "    maximo = data[coluna].max()\n",
    "    minimo = data[coluna].min()\n",
    "    # Atualiza a média (inicialmente inicializada com '-') no DataFrame de estatísticas\n",
    "    if not np.isnan(media):\n",
    "        tabela_estatisticas.at[coluna, 'Média/Moda'] = f\"{media:.2f}\"\n",
    "    # Atualiza o desvio padrão no DataFrame de estatísticas\n",
    "    if not np.isnan(desvio_padrao):\n",
    "        tabela_estatisticas.at[coluna, 'Desvio_Padrão (%)'] = f\"{(desvio_padrao / media) * 100:.2f}%\"\n",
    "    # Atualiza o valor máximo no DataFrame de estatísticas\n",
    "    if not np.isnan(maximo):\n",
    "        tabela_estatisticas.at[coluna, 'Máximo'] = f\"{maximo:.2f}\"\n",
    "    # Atualiza o valor mínimo no DataFrame de estatísticas\n",
    "    if not np.isnan(minimo):\n",
    "        tabela_estatisticas.at[coluna, 'Mínimo'] = f\"{minimo:.2f}\"\n",
    "        \n",
    "# Seleciona as colunas categórias do DataFrame\n",
    "colunas_categoricas = data.select_dtypes(include=['object']).columns\n",
    "# Calcula a moda para colunas categóricas\n",
    "for coluna in colunas_categoricas:\n",
    "    if coluna in tabela_estatisticas.index:\n",
    "        moda = data[coluna].mode().iloc[0]  # obtém a moda da coluna 'coluna' do DataFrame 'data' e seleciona o primeiro valor dessa moda.\n",
    "        tabela_estatisticas.at[coluna, 'Média/Moda'] = moda\n",
    "\n",
    "\n",
    "\n",
    "# Formata a tabela para centralizar o conteúdo das células e o cabeçalho\n",
    "#tabela_estatisticas_estilizada = tabela_estatisticas.style.set_properties(**{'text-align': 'center'}) \\\n",
    "#    .set_table_styles([{'selector': 'th', 'props': [('text-align', 'center')]}])\n",
    "\n",
    "# Exibe a tabela de estatísticas\n",
    "#tabela_estatisticas_estilizada\n",
    "\n",
    "\n",
    "\n",
    "tabela_estatisticas_formatada = pd.DataFrame()\n",
    "\n",
    "for coluna in tabela_estatisticas.columns:\n",
    "    # Adiciona a coluna ao DataFrame formatado\n",
    "    tabela_estatisticas_formatada[coluna] = tabela_estatisticas[coluna].apply(lambda x: f\"{x:.2f}\" if isinstance(x, float) else x)\n",
    "\n",
    "tabela_estatisticas_formatada"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51a765fc425e8085"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define o estilo do seaborn para os gráficos \n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Obtem a lista de colunas do DataFrame\n",
    "lista_colunas = data.columns\n",
    "\n",
    "# Define o número de colunas para o layout dos subplots\n",
    "num_cols = 3\n",
    "num_rows = int(np.ceil(len(lista_colunas) / num_cols)) # Calcula o número de linhas necessárias com base na quantidade de colunas\n",
    "\n",
    "#Cria uma grelha de subplots com o tamanho especificado\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 6, num_rows * 5))\n",
    "\n",
    "# Transforma o array de eixos  numa lista para facilitar a iteração\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Itera sobre cada coluna na lista de colunas\n",
    "for i, coluna in enumerate(lista_colunas):\n",
    "    ax = axes[i] #Seleciona o subplot atual\n",
    "    \n",
    "    # Verifica se a coluna é do tipo categórico (texto)\n",
    "    if data[coluna].dtype == 'object':\n",
    "        # Cria um gráfico de barras para colunas categóricas\n",
    "        sns.countplot(x=coluna, data=data, palette=\"viridis\", ax=ax)\n",
    "        # Define o título e rótulos do gráfico\n",
    "        ax.set_title(f'Histograma para a Categoria: {coluna}', fontsize=15)\n",
    "        ax.set_xlabel(coluna, fontsize=12)\n",
    "        ax.set_ylabel('Número de pacientes', fontsize=12)\n",
    "        # Rotaciona os rótulos do eixo x para melhor visualização\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "        ax.tick_params(axis='y', labelsize=10)\n",
    "        \n",
    "        # Adiciona a contagem acima das barras\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f'{int(p.get_height()):,}', (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                        ha='center', va='center', fontsize=10, color='black', xytext=(0, 5), \n",
    "                        textcoords='offset points')\n",
    "    else:\n",
    "       # Se a coluna for numérica, cria intervalos e agrupa os valores\n",
    "        valores_min = data[coluna].min()\n",
    "        valores_max = data[coluna].max()\n",
    "        intervalos = np.linspace(valores_min, valores_max, num=15)\n",
    "        \n",
    "        # Agrupa os valores numéricos em intervalos\n",
    "        data[coluna+'_intervalo'] = pd.cut(data[coluna], bins=intervalos, include_lowest=True)\n",
    "        \n",
    "        # Cria o histograma com os valores agrupados\n",
    "        sns.countplot(x=coluna+'_intervalo', data=data, palette=\"viridis\", ax=ax)\n",
    "       # Define o título e rótulos do gráfico\n",
    "        ax.set_title(f'Histograma para a Categoria: {coluna}', fontsize=15)\n",
    "        ax.set_xlabel(coluna, fontsize=12)\n",
    "        ax.set_ylabel('Número de pacientes', fontsize=12)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "        ax.tick_params(axis='y', labelsize=10)\n",
    "        \n",
    "        # Renomeia os rótulos do eixo x com os intervalos\n",
    "        labels = [f'{intervalos[j]:.2f} - {intervalos[j+1]:.2f}' for j in range(len(intervalos)-1)]\n",
    "        ax.set_xticklabels(labels)\n",
    "        \n",
    "        # Adiciona a contagem acima das barras\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f'{int(p.get_height()):,}', (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                        ha='center', va='center', fontsize=10, color='black', xytext=(0, 5), \n",
    "                        textcoords='offset points')\n",
    "\n",
    "# Identifica as colunas de intervalos temporárias que foram adicionadas\n",
    "colunas_para_remover = [coluna for coluna in data.columns if coluna.endswith('_intervalo')]\n",
    "\n",
    "# Remove as colunas de intervalos do DataFrame\n",
    "data = data.drop(columns=colunas_para_remover)\n",
    "# Lista as colunas restantes no DataFrame após a remoção\n",
    "colunas_restantes = data.columns.tolist()\n",
    "\n",
    "# Remove subplots vazios\n",
    "for j in range(i + 1, num_rows * num_cols):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout() #para evitar sobreposições\n",
    "plt.show() #exibe os histogramas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc4f57b5cb0891dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cria uma cópia do DataFrame original\n",
    "data2 = data.copy()\n",
    "\n",
    "# Substitui os valores 'Lives' por 1 e 'Dies' por 0 na coluna 'Class'\n",
    "data2['Class'] = data2['Class'].replace({'Lives': 1, 'Dies': 0})\n",
    "\n",
    "# Substitui os valores 'Yes' por 1 e 'No' por 0 em todas as colunas do DataFrame (tivemos de fazer desta forma porque senão a substuituição não estava a ser bem feita)\n",
    "data2 = data2.replace({'Yes': f'{1:.0f}', 'No': f'{0:.0f}'})\n",
    "data2=data2.replace({'Male': 0, 'Female': 1}) #substitui os valores 'Male' por 0 e 'Female' por 1\n",
    "\n",
    "data2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f003c840ddcbaac2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extrai a coluna de correlação da característica 'Class' da matriz de correlação\n",
    "correlacoes_com_class = matriz_correlacao['Class'].copy()\n",
    "\n",
    "# Remove a correlação da coluna 'Class' com ela mesma\n",
    "correlacoes_com_class = correlacoes_com_class.drop(labels=['Class'])\n",
    "\n",
    "# Ordena as correlações absolutas de forma decrescente, para uma melhor visualização \n",
    "correlacoes_com_class = correlacoes_com_class.abs().sort_values(ascending=False)\n",
    "\n",
    "# Exibe as correlações das variáveis com a variável com 'Class'\n",
    "print(\"Variáveis mais correlacionadas com 'Class':\")\n",
    "print(correlacoes_com_class)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c055e40e01f561aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remoção de Características Redundantes\n",
    "# Define as colunas que se vai remover(feito com base na menor correlação)\n",
    "colunas_para_remover = ['Packs_year', 'Nodules', 'CRI', 'Smoking', 'AHT', 'NASH', 'Varices', 'HBcAb', 'Hemochro', 'Sat', 'PHT', 'Alcohol', 'Cirrhosis', 'HBSAg', 'Spleno', 'Grams_day',  'Hallmark', 'Obesity', 'Sat', 'MCV', 'TP', 'ALT', 'AFP', 'HIV', 'Gender']\n",
    "\n",
    "# Remove as colunas se estiverem na lista de colunas para remover e no DataFrame \n",
    "data2 = data2.drop(columns=[coluna for coluna in colunas_para_remover if coluna in data2.columns])\n",
    "\n",
    "# Converte os nomes das colunas do DataFrame 'data2' para uma lista\n",
    "colunas_restantes = data2.columns.tolist()\n",
    "\n",
    "print(colunas_restantes)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c125885981c753a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data2 #para visualizarmos após se ter removido colunas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f734f0c8557d72"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imputação para colunas numéricas e categóricas\n",
    "for column in data2.columns:\n",
    "    if set(data2[column].unique()) == {0, 1}:  # Se contém apenas 0 e 1\n",
    "        data2[column].fillna(data2[column].mode()[0], inplace=True)  # Usa a moda\n",
    "    elif data2[column].dtype == 'object':  # Se for uma coluna categórica\n",
    "        data2[column].fillna(data2[column].mode()[0], inplace=True)  # Usa a moda\n",
    "    else:  # Caso contrário (numérica e diferente de 0 e de 1)\n",
    "        data2[column].fillna(data2[column].mean(), inplace=True)  # Usa a média\n",
    "data2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c42a579bcdd86621"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data2 = pd.get_dummies(data2) # converte variáveis categóricas em indicadoras\n",
    "data2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d9d813182760d79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# KNN\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # Importa a função para dividir o conjunto de dados\n",
    "from sklearn.preprocessing import StandardScaler  # Importa a função para normalizar os dados\n",
    "from sklearn.neighbors import KNeighborsClassifier  # Importa o classificador KNN\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, \\\n",
    "    roc_auc_score, roc_curve, f1_score  # Importa métricas para avaliação\n",
    "\n",
    "# Assume que a última coluna é a coluna alvo\n",
    "X = data2.iloc[:, :-1].values  # todas as colinas menos a ultima, como variaveis independentes\n",
    "y = data2.iloc[:, -1].values  # seleciona a ultima coluna como variavel dependente (alvo)\n",
    "\n",
    "# Divide os dados em conjuntos de treino e teste \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normaliza os dados (opcional, mas recomendado para KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Ajusta o normalizador\n",
    "X_test = scaler.transform(X_test)  # Transforma os dados de teste com o mesmo normalizador\n",
    "\n",
    "# Cria e treina o modelo KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # n_neighbors é o valor de K\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)  # previsoes com os dados de teste\n",
    "\n",
    "# Avalia a precisão do modelo\n",
    "accuracy_knn = accuracy_score(y_test, y_pred) * 100  # Converte para porcentagem\n",
    "print(f'Acurácia do modelo KNN: {accuracy_knn:.2f}%')\n",
    "\n",
    "# Calcula a precisão (precision) \n",
    "precision_knn = precision_score(y_test, y_pred, average='binary') * 100\n",
    "print(f'Precisão do modelo KNN: {precision_knn:.2f}')\n",
    "\n",
    "# Calcula o recall (sensibilidade)\n",
    "recall_knn = recall_score(y_test, y_pred, average='binary') * 100\n",
    "print(f'Recall (Sensibilidade) do modelo KNN: {recall_knn:.2f}%')\n",
    "\n",
    "# Matriz de Confusão\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred)  # calculo da matriz\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "sns.heatmap(conf_matrix_knn, annot=True, ax=axes[0], cmap='Blues', annot_kws={\"size\": 30})  # desenho da matriz\n",
    "axes[0].set_title('Matriz de Confusão - KNN', fontsize=25)\n",
    "axes[0].set_xlabel('Classe Predita', fontsize=25)\n",
    "axes[0].set_ylabel('Classe Real', fontsize=25)\n",
    "axes[0].tick_params(axis='x', labelsize=15)\n",
    "axes[0].tick_params(axis='y', labelsize=15)\n",
    "\n",
    "# Calcula o F1-Score\n",
    "knn_f1 = f1_score(y_test, y_pred, average='binary') * 100\n",
    "print(f'F1-Score do modelo KNN: {knn_f1:.2f}%')\n",
    "\n",
    "# Relatório de Classificação\n",
    "class_report_knn = classification_report(y_test, y_pred)\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(class_report_knn)\n",
    "\n",
    "# ROC e AUC (apenas para problemas binários)\n",
    "if len(set(y)) == 2:  # Verifica se é um problema binário\n",
    "    y_prob = knn.predict_proba(X_test)[:, 1]  # Probabilidade da classe positiva\n",
    "    auc_knn = roc_auc_score(y_test, y_prob)  # calcula a AUC\n",
    "    print(f'AUC: {auc_knn:.2f}')\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)  # Calcula a curva ROC\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {auc_knn:.2f})')  # desenha acurva ROC\n",
    "    plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')  # linha de referencia\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')  # eixo do x\n",
    "    plt.ylabel('True Positive Rate')  # eixo do y\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5332d65376bedb69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # importa o classificador da Árvore de decisão\n",
    "\n",
    "# Divide os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "# Normaliza os dados (opcional, mas pode ajudar em alguns modelos)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train) # ajusta o normalizador\n",
    "X_test = scaler.transform(X_test) # transforma os dados de teste com o normalizador\n",
    "\n",
    "# Cria e treina o modelo de Árvore de Decisão\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Faz previsões no conjunto de teste\n",
    "y_pred_dt = dt.predict(X_test) \n",
    "\n",
    "# Avalia a precisão do modelo\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt) * 100  # Converte para porcentagem\n",
    "print(f'Acurácia do modelo de Árvore de Decisão: {accuracy_dt:.2f}%')\n",
    "\n",
    "# Calcula a precisão (precision) e o recall (sensibilidade)\n",
    "precision_dt = precision_score(y_test, y_pred_dt, average='binary') * 100  # Converte para porcentagem\n",
    "print(f'Precisão do modelo de Árvore de Decisão: {precision_dt:.2f}%')\n",
    "\n",
    "# Calcula a precisão (precision) e o recall (sensibilidade)\n",
    "recall_dt = recall_score(y_test, y_pred_dt, average='binary') * 100  # Converte para porcentagem\n",
    "print(f'Recall (Sensibilidade) do modelo de Árvore de Decisão: {recall_dt:.2f}%')\n",
    "\n",
    "# Matriz de Confusão\n",
    "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "#print(conf_matrix)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "sns.heatmap(conf_matrix_dt, annot=True, fmt='d', ax=axes[1], cmap='Greens', annot_kws={\"size\": 30}) # desenho da matriz\n",
    "axes[1].set_title('Matriz de Confusão - Árvore de Decisão', fontsize=26)\n",
    "axes[1].set_xlabel('Classe Predita', fontsize=26)\n",
    "axes[1].set_ylabel('Classe Real', fontsize=25)\n",
    "axes[1].tick_params(axis='x', labelsize=15)\n",
    "axes[1].tick_params(axis='y', labelsize=15)\n",
    "\n",
    "# Calcula o F1-Score\n",
    "dt_f1 = f1_score(y_test, y_pred_dt, average='binary') * 100\n",
    "print(f'F1-Score do modelo KNN: {dt_f1:.2f}%')\n",
    "\n",
    "#Relatório de Classificação\n",
    "class_report_dt = classification_report(y_test, y_pred_dt)\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(class_report_dt)\n",
    "\n",
    "# ROC e AUC (apenas para problemas binários)\n",
    "if len(set(y)) == 2:  # Verifica se é um problema binário\n",
    "    y_prob = dt.predict_proba(X_test)[:, 1]  # Probabilidade da classe positiva\n",
    "    auc_dt = roc_auc_score(y_test, y_prob) # calculo da AUC\n",
    "    print(f'AUC: {auc_dt:.2f}')\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob) # calcula a curva ROC\n",
    "    plt.figure() # nova figura\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {auc_dt:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate') # eixo x\n",
    "    plt.ylabel('True Positive Rate') # eixo y\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7df553c2f9d8d13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# COMPARACAO DOS DOIS MODELOS\n",
    "\n",
    "from sklearn.model_selection import learning_curve # calcula as curvas de aprendizagem\n",
    "from sklearn.model_selection import StratifiedKFold # avaliacao das curvas de aprendizagem - validacao cruzada\n",
    "from sklearn.neighbors import KNeighborsClassifier # classificador KNN\n",
    "from sklearn.tree import DecisionTreeClassifier # classificador da Arvore de decisao\n",
    "from sklearn.datasets import load_digits # carrega o conjunto de dados\n",
    "\n",
    "print('Curva de Aprendizagem') # Variacao da acurácia com o tamanho do conjunto de treinamento\n",
    "\n",
    "\n",
    "# Carregar o conjunto de dados (como exemplo, usaremos o conjunto de dados de dígitos)\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "# Definir modelos que você deseja avaliar (KNN e Árvore de Decisão)\n",
    "models = {'KNN': KNeighborsClassifier(), 'Decision Tree': DecisionTreeClassifier()}\n",
    "\n",
    "# Definir os tamanhos dos conjuntos de treinamento para a curva de aprendizado\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "\n",
    "# Configurar a validação cruzada k-fold\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Plotar a curva de aprendizado para cada modelo\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "colors = {'KNN': {'Training': 'blue', 'Cross-validation': 'yellow'},\n",
    "          'Decision Tree': {'Training': 'green', 'Cross-validation': 'pink'}}\n",
    "\n",
    "# gera a curva de aprendizagem para os modelos \n",
    "for model_name, model in models.items():\n",
    "    train_sizes_abs, train_scores, test_scores = learning_curve(model, X, y, train_sizes=train_sizes, cv=cv, scoring='accuracy')\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    # areas de variancia\n",
    "    plt.fill_between(train_sizes_abs, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=colors[model_name]['Training'])\n",
    "    plt.fill_between(train_sizes_abs, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=colors[model_name]['Cross-validation'])\n",
    "    \n",
    "    plt.plot(train_sizes_abs, train_scores_mean, 'o-', color=colors[model_name]['Training'], label=f\"{model_name} Training score\")\n",
    "    plt.plot(train_sizes_abs, test_scores_mean, 'o-', color=colors[model_name]['Cross-validation'], label=f\"{model_name} Cross-validation score\")\n",
    "\n",
    "# configuracoes do grafico\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Learning Curves\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Desenha as curvas ROC para KNN e Árvore de Decisão juntas\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Desenha curva ROC para KNN\n",
    "fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, knn.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr_knn, tpr_knn, color='blue', lw=2, label=f'ROC curve KNN (area = {auc_knn:.2f})')\n",
    "\n",
    "# Desenha curva ROC para Árvore de Decisão\n",
    "fpr_dt, tpr_dt, thresholds_dt = roc_curve(y_test, dt.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr_dt, tpr_dt, color='green', lw=2, label=f'ROC curve Decision Tree (area = {auc_dt:.2f})')\n",
    "\n",
    "# Desenha linha de referência\n",
    "plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--')\n",
    "\n",
    "# configuracoes do grafico\n",
    "plt.xlim([0.0, 1.0]) # limites\n",
    "plt.ylim([0.0, 1.05]) # limites\n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Desenho histogramas para Acurácia, Precisão, Recall/Sensibilidade e F1-Score em uma linha\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# Histograma para Acurácia\n",
    "axs[0].bar(['KNN', 'Decision Tree'], [accuracy_knn, accuracy_dt], color=['blue', 'green'])\n",
    "axs[0].set_xlabel('Model')\n",
    "axs[0].set_ylabel('Accuracy (%)')\n",
    "axs[0].set_title('Accuracy of Models')\n",
    "# Adicionar porcentagem nas barras\n",
    "for i, v in enumerate([accuracy_knn, accuracy_dt]):\n",
    "    axs[0].text(i, v + 1, f'{v:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "# Histograma para Precisão\n",
    "axs[1].bar(['KNN', 'Decision Tree'], [precision_knn, precision_dt], color=['blue', 'green'])\n",
    "axs[1].set_xlabel('Model')\n",
    "axs[1].set_ylabel('Precision (%)')\n",
    "axs[1].set_title('Precision of Models')\n",
    "# Adicionar porcentagem nas barras\n",
    "for i, v in enumerate([precision_knn, precision_dt]):\n",
    "    axs[1].text(i, v + 1, f'{v:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "# Histograma para Recall/Sensibilidade\n",
    "axs[2].bar(['KNN', 'Decision Tree'], [recall_knn, recall_dt], color=['blue', 'green'])\n",
    "axs[2].set_xlabel('Model')\n",
    "axs[2].set_ylabel('Recall/Sensitivity (%)')\n",
    "axs[2].set_title('Recall/Sensitivity of Models')\n",
    "# Adicionar porcentagem nas barras\n",
    "for i, v in enumerate([recall_knn, recall_dt]):\n",
    "    axs[2].text(i, v + 1, f'{v:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "# Histograma para F1-Score\n",
    "axs[3].bar(['KNN', 'Decision Tree'], [knn_f1, dt_f1], color=['blue', 'green'])\n",
    "axs[3].set_xlabel('Model')\n",
    "axs[3].set_ylabel('F1-Score (%)')\n",
    "axs[3].set_title('F1-Score of Models')\n",
    "# Adicionar porcentagem nas barras\n",
    "for i, v in enumerate([knn_f1, dt_f1]):\n",
    "    axs[3].text(i, v + 1, f'{v:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Criar DataFrame com os valores das métricas\n",
    "tabela = {\n",
    "    'Modelo': ['KNN', 'Decision Tree'],\n",
    "    'Accuracy (%)': [accuracy_knn, accuracy_dt],\n",
    "    'Precision (%)': [precision_knn, precision_dt],\n",
    "    'Recall/Sensitivity (%)': [recall_knn, recall_dt],\n",
    "    'F1-Score (%)': [knn_f1, dt_f1]\n",
    "}\n",
    "\n",
    "# Criar DataFrame\n",
    "tabela_metrics = pd.DataFrame(tabela)\n",
    "\n",
    "# Definir as métricas como índices\n",
    "tabela_metrics.set_index('Modelo', inplace=True)\n",
    "\n",
    "# Exibir a tabela\n",
    "tabela_metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6d6a2ebf541f96e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
